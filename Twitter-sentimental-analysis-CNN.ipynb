{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>try to have as good a life as you can under th...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realdonaldtrump full of yourself ? ? remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politicomag o man woman if we had mr . truman...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>two and a half hours late to work</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>michael tarallo is now following me on twitter...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_text  label  split\n",
       "0  try to have as good a life as you can under th...      0  train\n",
       "1   realdonaldtrump full of yourself ? ? remember...      0  train\n",
       "2   politicomag o man woman if we had mr . truman...      0  train\n",
       "3                 two and a half hours late to work       0  train\n",
       "4  michael tarallo is now following me on twitter...      0  train"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./twitter_new.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9252174250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in train_df['post_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>try to have as good a life as you can under th...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[try, to, have, as, good, life, as, you, can, ...</td>\n",
       "      <td>[try, to, have, as, good, life, as, you, can, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realdonaldtrump full of yourself ? ? remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[realdonaldtrump, full, of, yourself, remember...</td>\n",
       "      <td>[realdonaldtrump, full, of, yourself, rememb, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politicomag o man woman if we had mr . truman...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[politicomag, man, woman, if, we, had, mr, tru...</td>\n",
       "      <td>[politicomag, man, woman, if, we, had, mr, tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>two and a half hours late to work</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[two, and, half, hours, late, to, work]</td>\n",
       "      <td>[two, and, half, hour, late, to, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>michael tarallo is now following me on twitter...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[michael, tarallo, is, now, following, me, on,...</td>\n",
       "      <td>[michael, tarallo, is, now, follow, me, on, tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>i m glad i was able to defend myself , said a...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>[glad, was, able, to, defend, myself, said, yr...</td>\n",
       "      <td>[glad, wa, abl, to, defend, myself, said, yr, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>thinking too much to sleep man this always hap...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>[thinking, too, much, to, sleep, man, this, al...</td>\n",
       "      <td>[think, too, much, to, sleep, man, thi, alwai,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>rt samstrike thanks for all the love this year...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>[rt, samstrike, thanks, for, all, the, love, t...</td>\n",
       "      <td>[rt, samstrik, thank, for, all, the, love, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>aartorias unless that s not what you meant</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>[aartorias, unless, that, not, what, you, meant]</td>\n",
       "      <td>[aartoria, unless, that, not, what, you, meant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>pissed off seems to be my new default . maybe...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>[pissed, off, seems, to, be, my, new, default,...</td>\n",
       "      <td>[piss, off, seem, to, be, my, new, default, ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               post_text  label  split  \\\n",
       "0      try to have as good a life as you can under th...      0  train   \n",
       "1       realdonaldtrump full of yourself ? ? remember...      0  train   \n",
       "2       politicomag o man woman if we had mr . truman...      0  train   \n",
       "3                     two and a half hours late to work       0  train   \n",
       "4      michael tarallo is now following me on twitter...      0  train   \n",
       "...                                                  ...    ...    ...   \n",
       "19995   i m glad i was able to defend myself , said a...      1   test   \n",
       "19996  thinking too much to sleep man this always hap...      1   test   \n",
       "19997  rt samstrike thanks for all the love this year...      1   test   \n",
       "19998         aartorias unless that s not what you meant      1   test   \n",
       "19999   pissed off seems to be my new default . maybe...      1   test   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "0      [try, to, have, as, good, life, as, you, can, ...   \n",
       "1      [realdonaldtrump, full, of, yourself, remember...   \n",
       "2      [politicomag, man, woman, if, we, had, mr, tru...   \n",
       "3                [two, and, half, hours, late, to, work]   \n",
       "4      [michael, tarallo, is, now, following, me, on,...   \n",
       "...                                                  ...   \n",
       "19995  [glad, was, able, to, defend, myself, said, yr...   \n",
       "19996  [thinking, too, much, to, sleep, man, this, al...   \n",
       "19997  [rt, samstrike, thanks, for, all, the, love, t...   \n",
       "19998   [aartorias, unless, that, not, what, you, meant]   \n",
       "19999  [pissed, off, seems, to, be, my, new, default,...   \n",
       "\n",
       "                                          stemmed_tokens  \n",
       "0      [try, to, have, as, good, life, as, you, can, ...  \n",
       "1      [realdonaldtrump, full, of, yourself, rememb, ...  \n",
       "2      [politicomag, man, woman, if, we, had, mr, tru...  \n",
       "3                 [two, and, half, hour, late, to, work]  \n",
       "4      [michael, tarallo, is, now, follow, me, on, tw...  \n",
       "...                                                  ...  \n",
       "19995  [glad, wa, abl, to, defend, myself, said, yr, ...  \n",
       "19996  [think, too, much, to, sleep, man, thi, alwai,...  \n",
       "19997  [rt, samstrik, thank, for, all, the, love, thi...  \n",
       "19998    [aartoria, unless, that, not, what, you, meant]  \n",
       "19999  [piss, off, seem, to, be, my, new, default, ma...  \n",
       "\n",
       "[20000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "train_df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in train_df['tokenized_text']]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 500\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "# 0 for CBOW, 1 for skip-gram\n",
    "sg = 0\n",
    "OUTPUT_FOLDER = '/Users/sylnne/Documents/GitHub/twitter-sentiment-analysis/'\n",
    "# Function to train word2vec model\n",
    "def make_word2vec_model(train_df, padding, sg, min_count, size, workers, window):\n",
    "    if  padding:\n",
    "        #print(len(train))\n",
    "        temp_df = pd.Series(train_df['stemmed_tokens']).values\n",
    "        temp_df = list(temp_df)\n",
    "        temp_df.append(['pad'])\n",
    "        #print(str(size))\n",
    "        word2vec_file = OUTPUT_FOLDER + '2ata' + '_PAD.model'\n",
    "    w2v_model = Word2Vec(temp_df, min_count = min_count, size = size, workers = workers, window = window, sg = sg)\n",
    "\n",
    "    w2v_model.save(word2vec_file)\n",
    "    return w2v_model, word2vec_file\n",
    "\n",
    "# Train Word2vec model\n",
    "w2vmodel, word2vec_file = make_word2vec_model(train_df, padding=True, sg=sg, min_count=min_count, size=size, workers=workers, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4269\n"
     ]
    }
   ],
   "source": [
    "max_sen_len = train_df.stemmed_tokens.map(len).max()\n",
    "\n",
    "padding_idx = w2vmodel.wv.vocab['pad'].index\n",
    "print(padding_idx)\n",
    "def make_word2vec_vector_cnn(sentence):\n",
    "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "    i = 0\n",
    "    for word in sentence:\n",
    "        if word not in w2vmodel.wv.vocab:\n",
    "            padded_X[i] = 0\n",
    "        else:\n",
    "            padded_X[i] = w2vmodel.wv.vocab[word].index\n",
    "        i += 1\n",
    "    return torch.tensor(padded_X, dtype=torch.long, device=device).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sen_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4269"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      "0    7005\n",
      "1    6995\n",
      "Name: label, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "1    3005\n",
      "0    2995\n",
      "Name: label, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "   index                                     stemmed_tokens\n",
      "0  16831  [larrydocu, my, entir, year, made, with, harri...\n",
      "1  16015  [how, children, inherit, our, anxieti, http, c...\n",
      "2  15380  [mittengirl, xo, veganrevoiut, someth, alreadi...\n",
      "3    385  [adclaidekan, god, there, so, mani, good, on, ...\n",
      "4  11825  [hollist, sk, uvedomil, som, si, swan, ceram, ...\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(train_df, test_size=0.3, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(train_df[['stemmed_tokens']], \n",
    "                                                        train_df['label'], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Call the train_test_split\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 500\n",
    "NUM_FILTERS = 10\n",
    "\n",
    "#torch.nn.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[T, Tuple[T, T]], \n",
    "#stride: Union[T, Tuple[T, T]] = 1, padding: Union[T, Tuple[T, T]] = 0, \n",
    "#dilation: Union[T, Tuple[T, T]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros')\n",
    "\n",
    "class CnnTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes, window_sizes=(1,2,3,5)):\n",
    "        super(CnnTextClassifier, self).__init__()\n",
    "        w2vmodel = gensim.models.KeyedVectors.load(OUTPUT_FOLDER + '2ata_PAD.model')\n",
    "        weights = w2vmodel.wv\n",
    "        # With pretrained embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights.vectors), padding_idx=w2vmodel.wv.vocab['pad'].index)\n",
    "        \n",
    "        # like a python list, it was designed to store any desired number of nn.Module\n",
    "        self.convs = nn.ModuleList([\n",
    "                                   nn.Conv2d(1, NUM_FILTERS, [window_size, EMBEDDING_SIZE], padding=(window_size - 1, 0))\n",
    "                                   for window_size in window_sizes\n",
    "        ])\n",
    "    \n",
    "        self.fc = nn.Linear(NUM_FILTERS * len(window_sizes), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) # [B, T, E]\n",
    "\n",
    "        # Apply a convolution + max_pool layer for each window size\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        xs = []\n",
    "        for conv in self.convs:\n",
    "            x2 = torch.tanh(conv(x))\n",
    "            x2 = torch.squeeze(x2, -1)\n",
    "            x2 = F.max_pool1d(x2, x2.size(2))\n",
    "            xs.append(x2)\n",
    "        x = torch.cat(xs, 2)\n",
    "\n",
    "        # FC\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        probs = F.softmax(logits, dim = 1)\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label):\n",
    "    if label == 0:\n",
    "        return torch.tensor([0], dtype=torch.long, device=device)\n",
    "    elif label == 1:\n",
    "        return torch.tensor([1], dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28471\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "VOCAB_SIZE = len(w2vmodel.wv.vocab)\n",
    "print(VOCAB_SIZE)\n",
    "cnn_model = CnnTextClassifier(vocab_size=VOCAB_SIZE, num_classes=NUM_CLASSES)\n",
    "cnn_model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.0001)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1\n",
      "train_loss : 0.6714746914016348\n",
      "Epoch ran :1\n",
      "Epoch2\n",
      "train_loss : 0.6492676782906055\n",
      "Epoch ran :2\n",
      "Epoch3\n",
      "train_loss : 0.6411803438982794\n",
      "Epoch ran :3\n",
      "Epoch4\n",
      "train_loss : 0.6359310652485916\n",
      "Epoch ran :4\n",
      "Epoch5\n",
      "train_loss : 0.6330287629578795\n",
      "Epoch ran :5\n",
      "Epoch6\n",
      "train_loss : 0.6303169460552079\n",
      "Epoch ran :6\n",
      "Epoch7\n",
      "train_loss : 0.628464110574552\n",
      "Epoch ran :7\n",
      "Epoch8\n",
      "train_loss : 0.6259397853889636\n",
      "Epoch ran :8\n",
      "Epoch9\n",
      "train_loss : 0.6245042486701693\n",
      "Epoch ran :9\n",
      "Epoch10\n",
      "train_loss : 0.6217808362117836\n",
      "Epoch ran :10\n",
      "Input vector\n",
      "Probs\n",
      "tensor([[0.4306, 0.5694]], grad_fn=<SoftmaxBackward0>)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Open the file for writing loss\n",
    "loss_file_name = OUTPUT_FOLDER + '1cnn_class_big_loss_with_padding.csv'\n",
    "f = open(loss_file_name,'w')\n",
    "f.write('iter, loss')\n",
    "f.write('\\n')\n",
    "losses = []\n",
    "\n",
    "cnn_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch\" + str(epoch + 1))\n",
    "    train_loss = 0\n",
    "\n",
    "    for index, row in X_train.iterrows():\n",
    "        # Clearing the accumulated gradients\n",
    "        cnn_model.zero_grad()\n",
    "\n",
    "        # Make the bag of words vector for stemmed tokens \n",
    "        bow_vec = make_word2vec_vector_cnn(row['stemmed_tokens'])\n",
    "       \n",
    "        # Forward pass to get output\n",
    "        probs = cnn_model(bow_vec)\n",
    "\n",
    "        # Get the target label\n",
    "        #print(Y_train['label'][index])\n",
    "        target = make_target(Y_train['label'][index])\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = loss_function(probs, target)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'train_loss : {train_loss / len(X_train)}')\n",
    "    print(\"Epoch ran :\"+ str(epoch+1))\n",
    "    \n",
    "    f.write(str((epoch+1)) + \",\" + str(train_loss / len(X_train)))\n",
    "    f.write('\\n')\n",
    "    train_loss = 0\n",
    "\n",
    "torch.save(cnn_model, OUTPUT_FOLDER + 'cnn_big_model_500_with_padding.pth')\n",
    "\n",
    "f.close()\n",
    "print(\"Input vector\")\n",
    "print(\"Probs\")\n",
    "print(probs)\n",
    "print(torch.argmax(probs, dim=1).cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['iter', ' loss'], dtype='object')\n",
      "[[2281  714]\n",
      " [1449 1556]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68      2995\n",
      "           1       0.69      0.52      0.59      3005\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.65      0.64      0.63      6000\n",
      "weighted avg       0.65      0.64      0.63      6000\n",
      "\n",
      "Index(['iter', ' loss'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bow_cnn_predictions = []\n",
    "original_lables_cnn_bow = []\n",
    "cnn_model.eval()\n",
    "loss_df = pd.read_csv(OUTPUT_FOLDER + '1cnn_class_big_loss_with_padding.csv')\n",
    "print(loss_df.columns)\n",
    "# loss_df.plot('loss')\n",
    "\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, row in X_test.iterrows():\n",
    "        #print(row['stemmed_tokens'])\n",
    "        bow_vec = make_word2vec_vector_cnn(row['stemmed_tokens'])\n",
    "        #print(bow_vec)\n",
    "        probs = cnn_model(bow_vec)\n",
    "        #print(probs.data)\n",
    "        _, predicted = torch.max(probs.data,  1)\n",
    "        \n",
    "        bow_cnn_predictions.append(predicted.cpu().numpy()[0])\n",
    "        original_lables_cnn_bow.append(make_target(Y_test['label'][index]).cpu().numpy()[0])\n",
    "\n",
    "print(confusion_matrix(original_lables_cnn_bow, bow_cnn_predictions))\n",
    "#print(original_lables_cnn_bow)\n",
    "print(classification_report(original_lables_cnn_bow,bow_cnn_predictions))\n",
    "loss_file_name = OUTPUT_FOLDER + '1cnn_class_big_loss_with_padding.csv'\n",
    "loss_df = pd.read_csv(loss_file_name)\n",
    "print(loss_df.columns)\n",
    "plt_500_padding_30_epochs = loss_df[' loss'].plot()\n",
    "fig = plt_500_padding_30_epochs.get_figure()\n",
    "fig.savefig(OUTPUT_FOLDER + '1loss_plt_500_padding_30_epochs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
